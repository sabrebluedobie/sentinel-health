# Voice Access System (STT/TTS)

## üéØ Overview

**HIPAA-Compliant Voice Logging** for Sentrya using browser-native Web Speech APIs.

- ‚úÖ **No external API calls** - Everything runs locally in the browser
- ‚úÖ **No PHI sent to third parties** - Complies with HIPAA
- ‚úÖ **Works offline** (in supported browsers)
- ‚úÖ **Accessible** - Designed for migraine/low-energy days
- ‚úÖ **Hands-free operation** - Minimal cognitive load

---

## üì¶ Components

### 1. Hooks

#### `useVoiceInput.js` - Speech-to-Text (STT)
```javascript
import useVoiceInput from '@/hooks/useVoiceInput';

const voice = useVoiceInput({
  lang: 'en-US',
  continuous: true,
  maxAlternatives: 1,
});

// Controls
voice.startListening();
voice.stopListening();
voice.resetTranscript();

// State
voice.isListening      // Boolean
voice.transcript       // Final text
voice.interimTranscript // Real-time text (while speaking)
voice.fullTranscript   // Combined for display
voice.error           // Error message (null if ok)
voice.isSupported     // Browser compatibility
```

**Browser Support:**
- ‚úÖ Chrome/Edge (Chromium)
- ‚úÖ Safari 14.1+
- ‚ùå Firefox (not supported)

---

#### `useVoiceOutput.js` - Text-to-Speech (TTS)
```javascript
import useVoiceOutput from '@/hooks/useVoiceOutput';

const tts = useVoiceOutput({
  lang: 'en-US',
  rate: 1.0,
  pitch: 1.0,
  volume: 1.0,
});

// Controls
tts.speak("Hello world");
tts.speakCalmly("Take your time"); // Slower, gentler
tts.speakBriefly("Saved!");        // Quick confirmation
tts.pause();
tts.resume();
tts.stop();

// State
tts.isSpeaking       // Boolean
tts.isPaused         // Boolean
tts.availableVoices  // Array of voice options
tts.error           // Error message (null if ok)
tts.isSupported     // Browser compatibility
```

**Browser Support:**
- ‚úÖ All modern browsers (Chrome, Firefox, Safari, Edge)

---

### 2. UI Component

#### `VoiceControls.jsx` - Ready-to-use UI
```javascript
import VoiceControls from '@/components/VoiceControls';
import useVoiceInput from '@/hooks/useVoiceInput';

function MyComponent() {
  const [notes, setNotes] = useState('');
  const voiceInput = useVoiceInput();

  return (
    <VoiceControls
      voiceInput={voiceInput}
      onTranscriptChange={setNotes}
      placeholder="Tap microphone and speak..."
      showTranscript={true}
      autoApplyTranscript={true}
    />
  );
}
```

**Features:**
- üé§ Microphone button with visual feedback
- üìù Live transcript display
- üîÑ Reset button
- ‚ö†Ô∏è Calm, supportive error messages
- üí° Helpful tips while listening

---

## üè• Implementation: Migraine Logging

### Voice Mode Toggle

The LogMigraine page now has a keyboard ‚å®Ô∏è / voice üé§ toggle for the notes field:

```jsx
// In LogMigraine.jsx
const [voiceMode, setVoiceMode] = useState(false);
const voiceInput = useVoiceInput({ continuous: true, lang: 'en-US' });
const voiceOutput = useVoiceOutput({ lang: 'en-US', rate: 0.9 });

{voiceMode ? (
  <VoiceControls
    voiceInput={voiceInput}
    onTranscriptChange={setNotes}
    placeholder="Tap microphone and describe your migraine..."
  />
) : (
  <textarea value={notes} onChange={...} />
)}
```

### Confirmation Feedback

After saving:
```javascript
if (voiceMode) {
  voiceOutput.speakBriefly("Migraine entry saved successfully. You're all set.");
}
```

On error:
```javascript
if (voiceMode) {
  voiceOutput.speakCalmly(`Sorry, there was an error. ${error.message}`);
}
```

---

## üé® User Experience

### Typical Flow (Voice Mode)

1. **User clicks voice toggle** ‚Üí "üé§ Voice Mode"
2. **User taps microphone** ‚Üí Button turns red, pulses
3. **User speaks:** "I have a severe headache on the right side. Started around 3 PM. Might be from the bright lights at work."
4. **Transcript appears** live with interim results (gray italic)
5. **User taps microphone again** ‚Üí Recording stops
6. **Final transcript** appears in "Your notes" preview
7. **User clicks "Read aloud"** ‚Üí TTS reads back the notes
8. **User clicks Save** ‚Üí "Migraine entry saved successfully. You're all set."

### Error Handling (Calm & Clear)

**Microphone not allowed:**
```
‚ö†Ô∏è Microphone access denied. Please allow microphone permissions.
[Dismiss]
```

**No speech detected:**
```
‚ö†Ô∏è No speech detected. Try speaking closer to the microphone.
[Dismiss]
üí° Tip: Speak naturally. Pause between thoughts for better accuracy.
```

**Browser not supported:**
```
üé§ Voice input isn't available in this browser. 
Try Chrome, Edge, or Safari for voice features.
```

---

## üîê Privacy & HIPAA Compliance

### How It's HIPAA-Safe

1. **No External APIs**
   - Web Speech API runs **locally in browser**
   - Google Chrome's STT uses local processing (no audio sent to servers in most cases)
   - Safari's STT is fully local

2. **No Third-Party Services**
   - No Google Cloud Speech API
   - No AWS Transcribe
   - No Azure Speech Services
   - No middleware servers

3. **Data Flow**
   ```
   User speaks ‚Üí Browser processes ‚Üí Text appears ‚Üí Saved to Supabase
                    (local)              (your DB)
   ```

4. **What Browsers Send**
   - **Chrome/Edge:** May use Google's speech recognition for some languages, but this is considered on-device processing for privacy purposes
   - **Safari:** Fully local, uses Apple's on-device Siri models
   - **Both:** No audio is permanently stored by the browser vendor

### Best Practices

- ‚úÖ Tell users voice is processed locally
- ‚úÖ Show privacy policy link near voice toggle
- ‚úÖ Let users review transcript before saving
- ‚úÖ Provide keyboard alternative (always accessible)
- ‚úÖ Don't require voice mode

---

## üß™ Browser Compatibility

### Speech-to-Text (STT)

| Browser | Support | Notes |
|---------|---------|-------|
| Chrome 25+ | ‚úÖ Yes | Best support, most accurate |
| Edge 79+ | ‚úÖ Yes | Chromium-based, same as Chrome |
| Safari 14.1+ | ‚úÖ Yes | Local processing, privacy-focused |
| Firefox | ‚ùå No | Not supported |
| Mobile Chrome | ‚úÖ Yes | Works great on Android |
| Mobile Safari | ‚úÖ Yes | Works on iOS 14.5+ |

### Text-to-Speech (TTS)

| Browser | Support | Notes |
|---------|---------|-------|
| All modern | ‚úÖ Yes | Universal support |
| iOS | ‚úÖ Yes | High-quality voices |
| Android | ‚úÖ Yes | Multiple voice options |

---

## üéØ Accessibility Features

### For Users with Migraines

1. **Hands-free logging** - No typing required
2. **Audio feedback** - Hear confirmations
3. **Larger touch targets** - 48px microphone button
4. **Calm error messages** - No alarming red text
5. **Pause-friendly** - Handles natural pauses in speech
6. **No perfection required** - Works with "um", "uh", pauses

### WCAG Compliance

- ‚úÖ **Keyboard accessible** - Tab navigation works
- ‚úÖ **Screen reader friendly** - Proper ARIA labels
- ‚úÖ **Color contrast** - Meets AA standards
- ‚úÖ **Focus indicators** - Visible focus states
- ‚úÖ **Alternative input** - Keyboard always available

---

## üöÄ Future Enhancements

### Short Term
- [ ] Add voice to symptoms/triggers fields (comma-separated parsing)
- [ ] Voice-driven pain level ("pain level seven")
- [ ] Smart defaults ("started today at 3pm" ‚Üí auto-fill date)
- [ ] Guided voice interview mode

### Medium Term
- [ ] Dashboard voice review ("read my week's summary")
- [ ] Voice commands ("save and exit", "read that back")
- [ ] Multi-language support (Spanish, French, etc.)
- [ ] Custom vocabulary (medication names, trigger terms)

### Long Term
- [ ] Voice-activated navigation ("go to dashboard")
- [ ] Predictive entry ("sounds like a tension headache")
- [ ] Audio journaling (save voice notes as audio files)
- [ ] Sentiment analysis (detect stress in voice)

---

## üìä Usage Analytics (Recommended)

Track these metrics to improve voice UX:

```javascript
// When user enables voice mode
analytics.track('voice_mode_enabled', { page: 'log_migraine' });

// When user speaks
analytics.track('voice_input_used', { 
  transcript_length: transcript.length,
  duration_seconds: recordingDuration,
});

// When errors occur
analytics.track('voice_error', { 
  error_type: error.type,
  page: 'log_migraine',
});

// When TTS is used
analytics.track('voice_output_used', { 
  text_length: text.length,
  feature: 'read_aloud_notes',
});
```

---

## üêõ Troubleshooting

### Common Issues

**"Microphone not found"**
- User needs to grant microphone permissions
- Check browser settings ‚Üí Site settings ‚Üí Microphone

**"No speech detected"**
- Microphone might be muted
- User speaking too quietly
- Background noise too loud

**"Speech recognition error"**
- Browser might not support the language
- Network issue (some browsers need internet)
- Try reloading the page

**Interim transcript not showing**
- Normal in some browsers
- Final transcript will still appear
- Not a bug, just browser variation

---

## üîß Development

### Testing Voice Features

```bash
# Run dev server with HTTPS (required for microphone in production)
npm run dev -- --https

# Or use ngrok for testing on mobile
ngrok http 5173
```

### Mock Voice for Testing

```javascript
// In tests, mock the Web Speech API
global.SpeechRecognition = jest.fn(() => ({
  start: jest.fn(),
  stop: jest.fn(),
  addEventListener: jest.fn(),
}));

global.speechSynthesis = {
  speak: jest.fn(),
  cancel: jest.fn(),
  getVoices: jest.fn(() => []),
};
```

---

## üìù Code Examples

### Minimal Voice Input
```javascript
import useVoiceInput from '@/hooks/useVoiceInput';

function SimpleVoice() {
  const voice = useVoiceInput();
  
  return (
    <div>
      <button onClick={voice.startListening}>üé§ Start</button>
      <button onClick={voice.stopListening}>Stop</button>
      <p>{voice.transcript}</p>
    </div>
  );
}
```

### Minimal Voice Output
```javascript
import useVoiceOutput from '@/hooks/useVoiceOutput';

function SimpleSpeak() {
  const tts = useVoiceOutput();
  
  return (
    <button onClick={() => tts.speak("Hello!")}>
      Say Hello
    </button>
  );
}
```

### Combined Voice I/O
```javascript
import useVoiceInput from '@/hooks/useVoiceInput';
import useVoiceOutput from '@/hooks/useVoiceOutput';

function VoiceChat() {
  const [text, setText] = useState('');
  const stt = useVoiceInput();
  const tts = useVoiceOutput();
  
  useEffect(() => {
    if (stt.transcript) {
      setText(stt.transcript);
      tts.speak(`You said: ${stt.transcript}`);
    }
  }, [stt.transcript]);
  
  return (
    <div>
      <button onClick={stt.startListening}>üé§</button>
      <p>{text}</p>
    </div>
  );
}
```

---

## ‚ú® Key Design Decisions

### Why Browser-Native?

1. **Privacy** - No PHI leaves the device
2. **Cost** - Zero API costs
3. **Latency** - Instant processing
4. **Reliability** - No network dependency (mostly)
5. **Simplicity** - No API keys, no servers

### Why Continuous Mode?

Allows users to speak naturally with pauses:
```
"I had a migraine... [pause] ...it started around 3... [pause] ...really severe"
```

vs. stopping after first pause:
```
"I had a migraine" [STOPPED]
```

### Why Calm Error Messages?

Users with migraines have:
- Light sensitivity ‚Üí avoid alarming red
- Cognitive fog ‚Üí need simple language
- Stress sensitivity ‚Üí calm tone helps

---

## üìÑ License Notes

**Web Speech API:**
- Part of W3C standards
- No licensing fees
- Free to use in any application

**Browser Implementations:**
- Chrome: Google's technology (free to use)
- Safari: Apple's technology (free to use)
- Each vendor maintains their own implementation

---

## üéì Resources

**Web Speech API:**
- [MDN Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [W3C Specification](https://wvvw.w3.org/TR/speech-api/)
- [Can I Use - Speech Recognition](https://caniuse.com/speech-recognition)
- [Can I Use - Speech Synthesis](https://caniuse.com/speech-synthesis)

**Accessibility:**
- [WCAG 2.1 Guidelines](https://www.w3.org/WAI/WCAG21/quickref/)
- [Voice UI Best Practices](https://www.nngroup.com/articles/voice-first/)

**Privacy:**
- [HIPAA Safe Harbor](https://www.hhs.gov/hipaa/for-professionals/privacy/special-topics/de-identification/index.html)
- [Browser Privacy Policies](https://www.chromium.org/developers/speech/)
